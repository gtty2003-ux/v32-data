import streamlit as st
import pandas as pd
import numpy as np
import os
import io
import json
from datetime import datetime, timedelta
import pytz
import yfinance as yf
from github import Github 
import time
from FinMind.data import DataLoader
import twstock
import matplotlib.colors as mcolors
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

# --- è¨­å®šé é¢è³‡è¨Š ---
st.set_page_config(
    page_title="V32 æˆ°æƒ…å®¤ (Drive Core)",
    layout="wide",
    page_icon="âš”ï¸"
)

# --- æ¨£å¼è¨­å®š ---
st.markdown("""
    <style>
    .stDataFrame thead tr th {
        background-color: #ffebee !important; 
        color: #b71c1c !important;
        font-weight: bold;
    }
    div[data-testid="stMetricValue"] {
        font-size: 24px;
        font-weight: bold;
    }
    .stButton>button {
        width: 100%;
        border-radius: 5px;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

# --- å…¨åŸŸè®Šæ•¸ ---
# é€™æ˜¯æ‚¨åº«å­˜æª”æ¡ˆçš„ Repoï¼Œç¶­æŒä¸è®Š
REPO_KEY = "gtty2003-ux/v32-data"
FILE_PATH = "holdings.csv"
# é€™æ˜¯ Google Drive æª”æ¡ˆ ID
DRIVE_FILE_ID = "19z2dUYPqfR4igRStWJMKUofdWCPfqQR_"

# --- è‡ªå®šç¾©æ·¡è‰²éš (Pastel Colormaps) ---
def make_pastel_cmap(hex_color):
    return mcolors.LinearSegmentedColormap.from_list("pastel_cmap", ["#ffffff", hex_color])

cmap_pastel_red   = make_pastel_cmap("#ef9a9a")
cmap_pastel_blue  = make_pastel_cmap("#90caf9")
cmap_pastel_green = make_pastel_cmap("#a5d6a7")

# --- å·¥å…·å‡½æ•¸ ---
def get_taiwan_time():
    utc_now = datetime.utcnow()
    tw_time = utc_now.replace(tzinfo=pytz.utc).astimezone(pytz.timezone('Asia/Taipei'))
    return tw_time.strftime("%Y-%m-%d %H:%M:%S")

def color_surplus(val):
    if not isinstance(val, (int, float)): return ''
    if val > 0: return 'color: #d32f2f; font-weight: bold;'
    elif val < 0: return 'color: #388e3c; font-weight: bold;'
    return 'color: black'

def color_action(val):
    val_str = str(val)
    if "è³£å‡º" in val_str or "åœæ" in val_str:
        return 'color: #ffffff; background-color: #d32f2f; font-weight: bold; padding: 5px; border-radius: 5px;'
    elif "çºŒæŠ±" in val_str:
        return 'color: #1b5e20; font-weight: bold;'
    return ''

# --- Google Drive é€£ç·š (ä¿®æ­£æ ¼å¼ç‰ˆ) ---
@st.cache_resource
def get_drive_service():
    # ç›´æ¥å°‡ JSON é‡‘é‘°å¯«åœ¨é€™è£¡
    service_account_info = {
      "type": "service_account",
      "project_id": "v32-stock-bot",
      "private_key_id": "d66f9a30ef7bae397ac2bbbdd24bb7919e96aa79",
      # â†“â†“â†“ æ³¨æ„é€™è£¡ï¼šæˆ‘åœ¨å­—ä¸²æœ€å¾Œé¢åŠ äº† .replace('\\n', '\n') ä¾†ä¿®æ­£æ›è¡Œå•é¡Œ â†“â†“â†“
      "private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC7kO+PAF/3PQ+x\nZWMwLuJbv/55RHgkcknK67FV2JWLDhWiASYnB/bp4AjCi1tBGuO/vvHk1U5gFElB\nTWbZmcr9BNzsC27MS9CxYM80VhhtOGMzM2+h3sBLk7H+Whj4yIaI+cf36/lL/WjL\nG2gHb3U0JXeC1JsDoDpUfBlJ/W7UswLMUF1ANorCocgsFg59gMVhWgzYKFs+lI1L\nFg1M3xu83iZKzoBrrXYHF+qOIOZtRVfkGYKMEvUPiUkOavXrHTFkD3ulGIbSEwa4\nhDXUoDVqPtMDgvMUVc8G8DlMVtFDUOOcEaKmJxY7NgWnXicQdm9SjmH/KCQYiFaj\nptJXMKlnAgMBAAECggEADR6OIwp7q+dxeY8F6RDedFxxiDnpzWLRFoh11vNXQmqx\nyKsb6A7+jk1FT5Y/w8YFuBu6/66L1NyWYyLu1rmTIS995GTIUzHaXw3OcHK1Mq6H\nAcXPQRs7iA3EnW3f4UblYh9WhVjUDySid9Jq7Fo3cHZObbBBR3elnNMxUaOQZQAh\nvAhbYJeFzACp8Tm5LFMAdjsS2VZrVGtSOIthAv7YSC+vXe3OmCGLuM6EAGIIBMP3\nXToWhY6r0uQfm9d0UfI0xiorWSGsNkBZPK6+HAJ6QVMQwMADHx3/4zOq1v7L0bAe\n+p6DIhCUasA475s4JQkTCCnQC2NM7aw2t/n1Esf3gQKBgQDkLd52g9Ai2facS5wA\nr6gOUUgE+Oh0Tv43PA2yc6pjtqOznx3QYAhY6fqaNgGCVsAwU1ZwnOzDY5LurZfy\nJ9b0UZcd1spN4nwGEobZtdxurzxIdUAoTf6/6ClGGXSpILLgAi06Q+Vu8f1zpx0Y\nnpBGSiTGqt8f5IXtko2WyHS0TwKBgQDSb2rJMi+LAcYXqqjUufSYKq3kxw2aYSR8\nQ+K9Opwv0Cu6u+6JSqHFakfvdNNq21LisjBR16CIQhSYCNzVqsjEbFSKTHYiJ6Dc\nLc8vvHE4ceOZFgljnoPKsnW/OX5enUJjgQNcSexnqJIqXA6VzWtLXXmtzZ7HY02r\nZtdGdlO7aQKBgHz8SxDr3sRYU+cE22zcytcc2rAuj1W2NzWWJYKMLNb1ofGvxKrx\nD2F0uJpj3qvATQGrhHum2WGlV0R5vfMcs3ecgYQMtT+4QWsqFseGADp4rjKaVww8\nvL/tsT3+j5JcoN5nEtMJgdElqEkDTsK/iBOYZVCVJCbaDCo3zmq7XoGtAoGBAKqw\ns1alfYjslGjIBhAfEfaHz+udRjxuBXFCg11oeB4UZhQeslrsjZGbJuRlx8OKSY4W\naTlJhS5hI2E69x3dXOJu2Jghc0U7DbDq+37GBLR7NNkM1erXPiGhZf8JPKa0OpCJ\nqlcmozplssHnT/FU4W4NUVCYU+15cBvS3FWMT1jZAoGAeVwwQjhPmyMV0QWfGOrq\n+W2MLdpY0x7nyrogcTayRa5e3rvWQpMYysi5wKNeC2h1SBrqt9uy0TzxmncfuzFp\nc/lTfnLyqlcTki+LOxdO3t1PhiBEdtwPKgYUy1pVFzobshJFUpT1rU5sqZ33Qrk0\nPXtnDwQ6aHVBjNXbvFCu3D4=\n-----END PRIVATE KEY-----\n".replace('\\n', '\n'),
      "client_email": "v32-auto-updater@v32-stock-bot.iam.gserviceaccount.com",
      "client_id": "109928194171724697312",
      "auth_uri": "https://accounts.google.com/o/oauth2/auth",
      "token_uri": "https://oauth2.googleapis.com/token",
      "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
      "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/v32-auto-updater%40v32-stock-bot.iam.gserviceaccount.com"
    }

    try:
        creds = service_account.Credentials.from_service_account_info(
            service_account_info, 
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        return build('drive', 'v3', credentials=creds)
    except Exception as e:
        st.error(f"GCP èªè­‰å¤±æ•—: {e}")
        return None

@st.cache_data(ttl=1800) # å¿«å– 30 åˆ†é˜ï¼Œå› ç‚ºé€™æ˜¯ç›¤å¾Œè³‡æ–™
def load_data_from_drive():
    service = get_drive_service()
    if not service: return pd.DataFrame()
    
    try:
        request = service.files().get_media(fileId=DRIVE_FILE_ID)
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
        fh.seek(0)
        df = pd.read_csv(fh)
        
        # ç¢ºä¿æ¬„ä½åç¨±æ­£ç¢º (ç›¸å®¹æ€§è™•ç†)
        # å¦‚æœæ˜¯ä¸­æ–‡ï¼Œè½‰æˆè‹±æ–‡ä»¥ä¾¿å¾ŒçºŒé‹ç®—
        rename_map = {
            'æ—¥æœŸ': 'Date', 'è‚¡ç¥¨ä»£ç¢¼': 'Code', 'è‚¡ç¥¨åç¨±': 'Name',
            'æˆäº¤è‚¡æ•¸': 'TradeVolume', 'æ”¶ç›¤åƒ¹': 'ClosingPrice',
            'é–‹ç›¤åƒ¹': 'OpeningPrice', 'æœ€é«˜åƒ¹': 'HighestPrice', 'æœ€ä½åƒ¹': 'LowestPrice'
        }
        df.rename(columns=rename_map, inplace=True)
        
        # è½‰å‹
        df['Code'] = df['Code'].astype(str).str.strip()
        df['Date'] = pd.to_datetime(df['Date'])
        numeric_cols = ['ClosingPrice', 'OpeningPrice', 'HighestPrice', 'LowestPrice', 'TradeVolume']
        for c in numeric_cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors='coerce')
                
        return df
    except Exception as e:
        st.error(f"ç„¡æ³•å¾ Drive ä¸‹è¼‰è³‡æ–™: {e}")
        return pd.DataFrame()

# --- V32 é‹ç®—æ ¸å¿ƒ (æ”¹ç‰ˆï¼šç›´æ¥é‹ç®— DataFrame) ---
def calculate_v32_score(df_group):
    # df_group æ˜¯ä¸€æ”¯è‚¡ç¥¨çš„æ­·å²è³‡æ–™ (å·²æŒ‰æ—¥æœŸæ’åº)
    if len(df_group) < 65: return None # è³‡æ–™ä¸è¶³

    df = df_group.sort_values('Date').reset_index(drop=True)
    close = df['ClosingPrice']
    vol = df['TradeVolume']
    high = df['HighestPrice']
    open_p = df['OpeningPrice']
    
    # æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
    ma5 = close.rolling(5).mean()
    ma20 = close.rolling(20).mean()
    ma60 = close.rolling(60).mean()
    
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    
    exp1 = close.ewm(span=12, adjust=False).mean()
    exp2 = close.ewm(span=26, adjust=False).mean()
    macd = exp1 - exp2
    signal = macd.ewm(span=9, adjust=False).mean()
    
    vol_ma5 = vol.rolling(5).mean()
    vol_ma20 = vol.rolling(20).mean()
    high_20 = high.rolling(20).max()
    
    # åªè¨ˆç®—æœ€è¿‘ä¸€å¤©çš„åˆ†æ•¸
    i = -1 
    
    c_now = close.iloc[i]
    if pd.isna(c_now): return None
    
    # æå–ç•¶å‰å€¼
    m5, m20, m60 = ma5.iloc[i], ma20.iloc[i], ma60.iloc[i]
    m20_prev = ma20.iloc[i-1]
    r_now = rsi.iloc[i]
    macd_now, sig_now = macd.iloc[i], signal.iloc[i]
    h20_prev = high_20.iloc[i-1]
    v_now, v_prev = vol.iloc[i], vol.iloc[i-1]
    v_m5, v_m20 = vol_ma5.iloc[i], vol_ma20.iloc[i]
    o_now = open_p.iloc[i]
    
    # è©•åˆ†é‚è¼¯
    t_score = 60
    if c_now > m20: t_score += 5
    if m20 > m20_prev: t_score += 5
    if m5 > m20 and m20 > m60: t_score += 10
    if r_now > 50: t_score += 5
    if r_now > 70: t_score += 5
    if macd_now > sig_now: t_score += 5
    if c_now > h20_prev: t_score += 10
    
    v_score = 60
    if v_now > v_m20: v_score += 10
    if v_now > v_m5: v_score += 10
    if c_now > o_now and v_now > v_prev: v_score += 15
    if v_now > v_m20 * 1.5: v_score += 5
    
    t_score = min(100, t_score)
    v_score = min(100, v_score)
    
    # æ”»æ“Šåˆ† (éœ€è¨ˆç®—æ˜¨å¤©çš„åˆ†æ•¸ä¾†åšåŠ æ¬Šï¼Œé€™è£¡ç°¡åŒ–è™•ç†ï¼Œè‹¥éœ€è¦ç²¾ç¢ºå¯å†å›æ¨ä¸€å¤©)
    # é€™è£¡æ¡ç”¨ç•¶æ—¥åˆ†æ•¸åšç‚ºä¸»è¦ä¾æ“šï¼Œæˆ–å¯ç”¨ç°¡å–®åŠ æ¬Š
    raw_today = (t_score * 0.7) + (v_score * 0.3)
    
    # ç©©å®šåº¦ (å›æ¨ 5 å¤©)
    stability_count = 0
    # ç°¡åŒ–ï¼šåªå›å‚³åˆ†æ•¸ï¼Œä¸é‡è¤‡è¨ˆç®— 5 å¤©çš„æ­·å²åˆ†ä»¥å…æ•ˆèƒ½éä½
    
    return {
        'æŠ€è¡“åˆ†': t_score, 
        'é‡èƒ½åˆ†': v_score, 
        'æ”»æ“Šåˆ†': raw_today, # æš«ä»¥ç•¶æ—¥åˆ†ç‚ºä¸»ï¼Œå› æ•ˆèƒ½è€ƒé‡
        'æ”¶ç›¤': c_now
    }

@st.cache_data(ttl=1800)
def process_drive_data():
    raw_df = load_data_from_drive()
    if raw_df.empty: return pd.DataFrame(), "ç„¡æ³•è®€å–æ•¸æ“š"
    
    # å¹³è¡Œé‹ç®—æˆ–ç¾¤çµ„é‹ç®—
    results = []
    grouped = raw_df.groupby('Code')
    
    # ç‚ºäº†é€²åº¦æ¢
    total_stocks = len(grouped)
    # p_bar = st.progress(0)
    
    for i, (code, group) in enumerate(grouped):
        # å–å‡ºåç¨± (å‡è¨­åŒä¸€ä»£ç¢¼åç¨±éƒ½ä¸€æ¨£ï¼Œå–æœ€å¾Œä¸€ç­†)
        name = group['Name'].iloc[-1]
        
        score_data = calculate_v32_score(group)
        if score_data:
            score_data['ä»£è™Ÿ'] = code
            score_data['åç¨±'] = name
            results.append(score_data)
        
        # if i % 50 == 0: p_bar.progress((i+1)/total_stocks)
    
    # p_bar.empty()
    return pd.DataFrame(results), None

# --- æ ¸å¿ƒé˜²é–æ©Ÿåˆ¶ (ç¶­æŒä¸è®Š) ---
@st.cache_data(ttl=60)
def get_realtime_quotes(code_list):
    if not code_list: return {}
    code_list = list(set([str(c).strip() for c in code_list]))
    realtime_data = {}
    chunk_size = 20
    chunks = [code_list[i:i + chunk_size] for i in range(0, len(code_list), chunk_size)]
    
    for chunk in chunks:
        try:
            stocks = twstock.realtime.get(chunk)
            if isinstance(stocks, dict): stocks = [stocks]
            if stocks:
                for stock in stocks:
                    if stock['success']:
                        code = stock['info']['code']
                        name = stock['info'].get('name', code) 
                        price_str = stock['realtime'].get('latest_trade_price', '-')
                        if price_str == '-' or not price_str:
                            price_str = stock['realtime'].get('best_bid_price', ['-'])[0]
                        last_close = float(stock['info']['last_price']) if stock['info']['last_price'] != '-' else 0.0
                        try: current_price = float(price_str)
                        except: current_price = 0.0
                        vol_str = stock['realtime'].get('accumulate_trade_volume', '0')
                        try: volume = int(vol_str)
                        except: volume = 0
                        
                        if current_price > 0:
                            change_pct = ((current_price - last_close) / last_close) * 100 if last_close > 0 else 0
                            realtime_data[code] = {
                                'åç¨±': name,
                                'å³æ™‚åƒ¹': current_price,
                                'æ¼²è·Œå¹…%': change_pct,
                                'ç•¶æ—¥é‡': volume,
                                'ä¾†æº': 'TWSE'
                            }
            time.sleep(0.2)
        except: pass

    # Yahoo å‚™æ´
    missing_codes = [c for c in code_list if c not in realtime_data]
    if missing_codes:
        try:
            yf_codes = [f"{c}.TW" for c in missing_codes]
            tickers = yf.Tickers(" ".join(yf_codes))
            for code in missing_codes:
                try:
                    ticker = tickers.tickers[f"{code}.TW"]
                    name = code 
                    price = ticker.fast_info.last_price
                    prev_close = ticker.fast_info.previous_close
                    try: volume = ticker.fast_info.last_volume
                    except: volume = 0
                    if price and price > 0:
                        change_pct = ((price - prev_close) / prev_close) * 100 if prev_close else 0
                        realtime_data[code] = {
                            'åç¨±': name,
                            'å³æ™‚åƒ¹': price,
                            'æ¼²è·Œå¹…%': change_pct,
                            'ç•¶æ—¥é‡': volume,
                            'ä¾†æº': 'Yahoo'
                        }
                except: continue
        except: pass
            
    return realtime_data

def merge_realtime_data(df):
    if df.empty: return df
    codes = df['ä»£è™Ÿ'].astype(str).tolist()
    rt_data = get_realtime_quotes(codes)
    df['å³æ™‚åƒ¹'] = df['ä»£è™Ÿ'].map(lambda x: rt_data.get(x, {}).get('å³æ™‚åƒ¹', np.nan))
    df['æ¼²è·Œå¹…%'] = df['ä»£è™Ÿ'].map(lambda x: rt_data.get(x, {}).get('æ¼²è·Œå¹…%', np.nan))
    df['ç•¶æ—¥é‡'] = df['ä»£è™Ÿ'].map(lambda x: rt_data.get(x, {}).get('ç•¶æ—¥é‡', 0))
    # è‹¥ç„¡å³æ™‚åƒ¹ï¼Œå›é€€ä½¿ç”¨æ˜¨æ”¶
    df['å³æ™‚åƒ¹'] = df['å³æ™‚åƒ¹'].fillna(df['æ”¶ç›¤'])
    df['æ¼²è·Œå¹…%'] = df['æ¼²è·Œå¹…%'].fillna(0)
    df['ç•¶æ—¥é‡'] = df['ç•¶æ—¥é‡'].fillna(0)
    return df

# --- FinMind ç±Œç¢¼åˆ†æ (ç¶­æŒä¸è®Š) ---
def get_chip_analysis(symbol_list):
    # (æ­¤éƒ¨åˆ†ä»£ç¢¼ç¶­æŒåŸæ¨£ï¼Œç¯‡å¹…è€ƒé‡çœç•¥ï¼Œè«‹ç›´æ¥ä½¿ç”¨æ‚¨åŸæœ¬çš„ FinMind å‡½å¼)
    chip_data = []
    dl = DataLoader()
    p_bar = st.progress(0)
    status = st.empty()
    total = len(symbol_list)
    start_date = (datetime.now() - timedelta(days=10)).strftime('%Y-%m-%d')
    for i, symbol in enumerate(symbol_list):
        status.text(f"ğŸ” åˆ†æç±Œç¢¼çµæ§‹: {symbol} ({i+1}/{total})...")
        p_bar.progress((i + 1) / total)
        try:
            df = dl.taiwan_stock_institutional_investors(stock_id=symbol, start_date=start_date)
            if df.empty:
                chip_data.append({'ä»£è™Ÿ': symbol, 'æŠ•ä¿¡(å¼µ)': 0, 'å¤–è³‡(å¼µ)': 0, 'ä¸»åŠ›å‹•å‘': 'âšª è³‡æ–™ä¸è¶³'})
                continue
            latest_date = df['date'].iloc[-1]
            day_data = df[df['date'] == latest_date]
            foreign_net = day_data[day_data['name'].str.contains('Foreign')]['buy'].sum() - day_data[day_data['name'].str.contains('Foreign')]['sell'].sum()
            foreign_buy = int(foreign_net // 1000)
            trust_net = day_data[day_data['name'] == 'Investment_Trust']['buy'].sum() - day_data[day_data['name'] == 'Investment_Trust']['sell'].sum()
            trust_buy = int(trust_net // 1000)
            status_str = ""
            if trust_buy > 0: status_str += "ğŸ”´ æŠ•ä¿¡è²· "
            elif trust_buy < 0: status_str += "ğŸŸ¢ æŠ•ä¿¡è³£ "
            if foreign_buy > 1000: status_str += "ğŸ”¥ å¤–è³‡å¤§è²· "
            elif foreign_buy < -1000: status_str += "ğŸ§Š å¤–è³‡å€’è²¨ "
            if trust_buy > 0 and foreign_buy > 0: final_tag = "ğŸš€ åœŸæ´‹åˆè²·"
            elif trust_buy > 0 and foreign_buy < 0: final_tag = "âš”ï¸ åœŸæ´‹å°ä½œ(ä¿¡)"
            elif trust_buy < 0 and foreign_buy > 0: final_tag = "âš”ï¸ åœŸæ´‹å°ä½œ(å¤–)"
            elif trust_buy < 0 and foreign_buy < 0: final_tag = "â˜ ï¸ ä¸»åŠ›æ£„å®ˆ"
            else: final_tag = "ğŸŸ¡ ä¸€èˆ¬è¼ªå‹•"
            chip_data.append({'ä»£è™Ÿ': symbol, 'æŠ•ä¿¡(å¼µ)': trust_buy, 'å¤–è³‡(å¼µ)': foreign_buy, 'ä¸»åŠ›å‹•å‘': f"{final_tag} | {status_str}"})
            time.sleep(0.05) 
        except:
            chip_data.append({'ä»£è™Ÿ': symbol, 'æŠ•ä¿¡(å¼µ)': 0, 'å¤–è³‡(å¼µ)': 0, 'ä¸»åŠ›å‹•å‘': 'âŒ Error'})
    p_bar.empty()
    status.empty()
    return pd.DataFrame(chip_data)

# --- åº«å­˜å­˜å– (ç¶­æŒ GitHub) ---
def load_holdings():
    try:
        token = st.secrets["general"]["GITHUB_TOKEN"]
        g = Github(token)
        repo = g.get_repo(REPO_KEY)
        contents = repo.get_contents(FILE_PATH)
        df = pd.read_csv(contents.download_url)
        rename_map = {'ä»£è™Ÿ': 'è‚¡ç¥¨ä»£è™Ÿ', 'Code': 'è‚¡ç¥¨ä»£è™Ÿ', 'Symbol': 'è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡æ•¸': 'æŒæœ‰è‚¡æ•¸', 'Shares': 'æŒæœ‰è‚¡æ•¸', 'å‡åƒ¹': 'è²·å…¥å‡åƒ¹', 'æˆæœ¬': 'è²·å…¥å‡åƒ¹', 'Price': 'è²·å…¥å‡åƒ¹', 'Cost': 'è²·å…¥å‡åƒ¹'}
        df = df.rename(columns=rename_map)
        df['è‚¡ç¥¨ä»£è™Ÿ'] = df['è‚¡ç¥¨ä»£è™Ÿ'].astype(str).str.strip()
        for c in ["è‚¡ç¥¨ä»£è™Ÿ", "è²·å…¥å‡åƒ¹", "æŒæœ‰è‚¡æ•¸"]:
            if c not in df.columns: df[c] = 0.0 if "åƒ¹" in c else (0 if "è‚¡" in c else "")
        return df[["è‚¡ç¥¨ä»£è™Ÿ", "è²·å…¥å‡åƒ¹", "æŒæœ‰è‚¡æ•¸"]]
    except: return pd.DataFrame(columns=["è‚¡ç¥¨ä»£è™Ÿ", "è²·å…¥å‡åƒ¹", "æŒæœ‰è‚¡æ•¸"])

def save_holdings(df):
    try:
        token = st.secrets["general"]["GITHUB_TOKEN"]
        g = Github(token)
        repo = g.get_repo(REPO_KEY)
        csv_content = df.to_csv(index=False)
        try:
            contents = repo.get_contents(FILE_PATH)
            repo.update_file(contents.path, f"Update {get_taiwan_time()}", csv_content, contents.sha)
            st.success("âœ… åº«å­˜å·²åŒæ­¥è‡³é›²ç«¯ï¼")
        except:
            repo.create_file(FILE_PATH, "Create holdings.csv", csv_content)
            st.success("âœ… å»ºç«‹ä¸¦å„²å­˜æˆåŠŸï¼")
    except Exception as e: st.error(f"âŒ å„²å­˜å¤±æ•—: {e}")

# --- ç¯©é¸èˆ‡æ’åºé‚è¼¯ (ç¶­æŒä¸è®Š) ---
def get_stratified_selection(df):
    if df.empty: return df, []
    cols = ['æ”»æ“Šåˆ†', 'æŠ€è¡“åˆ†', 'é‡èƒ½åˆ†']
    for c in cols: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    # ç¯©é¸æ¨™æº–ï¼šæŠ€è¡“åˆ†>60, é‡èƒ½>60, æ”»æ“Šåˆ†>80
    mask = (df['æŠ€è¡“åˆ†'] >= 60) & (df['é‡èƒ½åˆ†'] >= 60) & (df['æ”»æ“Šåˆ†'] >= 80)
    filtered = df[mask].copy()
    if filtered.empty: return pd.DataFrame(), ["ç„¡ç¬¦åˆæ¢ä»¶æ¨™çš„"]
    
    # åˆ†ç´š
    b_a = filtered[filtered['æ”»æ“Šåˆ†'] >= 90].sort_values('æ”»æ“Šåˆ†', ascending=False).head(5)
    b_b = filtered[(filtered['æ”»æ“Šåˆ†'] >= 85) & (filtered['æ”»æ“Šåˆ†'] < 90)].sort_values('æ”»æ“Šåˆ†', ascending=False).head(5)
    b_c = filtered[(filtered['æ”»æ“Šåˆ†'] >= 80) & (filtered['æ”»æ“Šåˆ†'] < 85)].sort_values('æ”»æ“Šåˆ†', ascending=False).head(5)
    
    final = pd.concat([b_a, b_b, b_c])
    stats = [f"90+: {len(b_a)}", f"85-90: {len(b_b)}", f"80-85: {len(b_c)}"]
    return final, stats

def get_raw_top10(df):
    if df.empty: return df
    df['æ”»æ“Šåˆ†'] = pd.to_numeric(df['æ”»æ“Šåˆ†'], errors='coerce').fillna(0)
    return df.sort_values(by='æ”»æ“Šåˆ†', ascending=False).head(10)

# --- ä¸»ç¨‹å¼ ---
def main():
    st.title("âš”ï¸ V32 æˆ°æƒ…å®¤ (Drive Core)")
    if 'inventory' not in st.session_state: st.session_state['inventory'] = load_holdings()
    if 'input_key_counter' not in st.session_state: st.session_state['input_key_counter'] = 0
    
    if st.button("ğŸ”„ åˆ·æ–°å³æ™‚å ±åƒ¹", type="primary"):
        st.cache_data.clear()
        st.rerun()

    # 1. è¼‰å…¥ Drive è³‡æ–™ä¸¦é‹ç®—åˆ†æ•¸
    with st.spinner("æ­£åœ¨è®€å– Google Drive æ ¸å¿ƒæ•¸æ“šä¸¦é€²è¡Œå…¨å¸‚å ´é‹ç®—... (æ¯æ—¥ä¸€æ¬¡)"):
        v32_df, err = process_drive_data()
        
    if err: st.error(err)
    if not v32_df.empty:
        v32_df['cat'] = v32_df.apply(lambda r: 'Special' if ('å‚µ' in str(r.get('åç¨±', '')) or 'KY' in str(r.get('åç¨±', '')) or str(r['ä»£è™Ÿ']).startswith(('00','91'))) else 'General', axis=1)
        v32_df = v32_df[v32_df['cat'] == 'General']
        st.caption(f"åˆ†æå®Œæˆ: å…± {len(v32_df)} æª”è‚¡ç¥¨ | è³‡æ–™ä¾†æº: Google Drive (æ¯æ—¥æ›´æ–°)")

    tab_strat, tab_raw, tab_inv = st.tabs(["ğŸ¯ V32 ç²¾é¸", "ğŸ† å…¨å¸‚å ´ Top 10", "ğŸ’¼ åº«å­˜ç®¡ç†"])
    fmt_score = {'å³æ™‚åƒ¹':'{:.2f}', 'æ¼²è·Œå¹…%':'{:+.2f}%', 'æ”»æ“Šåˆ†':'{:.1f}', 'æŠ€è¡“åˆ†':'{:.0f}', 'é‡èƒ½åˆ†':'{:.0f}', 'ç•¶æ—¥é‡':'{:,}', 'å¤–è³‡(å¼µ)': '{:,.0f}', 'æŠ•ä¿¡(å¼µ)': '{:,.0f}'}

    # === Tab 1: V32 ç²¾é¸ ===
    with tab_strat:
        if not v32_df.empty:
            final_df, stats = get_stratified_selection(v32_df)
            st.info(f"ğŸ¯ æˆ°ç•¥çµæ§‹ï¼š{' | '.join(stats)}")
            if not final_df.empty:
                # å–å¾—å³æ™‚å ±åƒ¹ (é‡å°ç¯©é¸å‡ºä¾†çš„å°‘æ•¸è‚¡ç¥¨)
                final_df = merge_realtime_data(final_df)
                
                col_btn, col_info = st.columns([1, 4])
                with col_btn:
                    scan_chip = st.button("ğŸš€ ç±Œç¢¼æƒæ", key="btn_strat_scan")
                if scan_chip:
                    with st.spinner("åˆ†æç±Œç¢¼ä¸­..."):
                        chip_df = get_chip_analysis(final_df['ä»£è™Ÿ'].tolist())
                        if not chip_df.empty: final_df = pd.merge(final_df, chip_df, on='ä»£è™Ÿ', how='left')

                final_df = final_df.sort_values(['æ”»æ“Šåˆ†', 'æ¼²è·Œå¹…%'], ascending=[False, False])
                cols_to_show = ['ä»£è™Ÿ','åç¨±','å³æ™‚åƒ¹','æ¼²è·Œå¹…%','æŠ€è¡“åˆ†','é‡èƒ½åˆ†','æ”»æ“Šåˆ†']
                if 'ä¸»åŠ›å‹•å‘' in final_df.columns: cols_to_show += ['ä¸»åŠ›å‹•å‘', 'æŠ•ä¿¡(å¼µ)', 'å¤–è³‡(å¼µ)']
                
                st.dataframe(
                    final_df[cols_to_show].style
                    .format(fmt_score)
                    .background_gradient(subset=['æ”»æ“Šåˆ†'], cmap=cmap_pastel_red)
                    .background_gradient(subset=['æŠ€è¡“åˆ†'], cmap=cmap_pastel_blue)
                    .background_gradient(subset=['é‡èƒ½åˆ†'], cmap=cmap_pastel_green)
                    .map(color_change, subset=['æ¼²è·Œå¹…%']), 
                    hide_index=True,
                    use_container_width=True
                )
            else: st.warning("ç„¡ç¬¦åˆ V32 æ¢ä»¶æ¨™çš„")
        else: st.warning("æš«ç„¡è³‡æ–™")

    # === Tab 2: Top 10 ===
    with tab_raw:
        st.markdown("### ğŸ† å…¨å¸‚å ´æ”»æ“ŠåŠ›æ’è¡Œ (Top 10)")
        if not v32_df.empty:
            raw_df = get_raw_top10(v32_df)
            if not raw_df.empty:
                raw_df = merge_realtime_data(raw_df)
                if st.button("ğŸš€ ç±Œç¢¼æƒæ (Top 10)", key="btn_raw_scan"):
                    with st.spinner("åˆ†æç±Œç¢¼ä¸­..."):
                        chip_df = get_chip_analysis(raw_df['ä»£è™Ÿ'].tolist())
                        if not chip_df.empty: raw_df = pd.merge(raw_df, chip_df, on='ä»£è™Ÿ', how='left')

                cols_to_show = ['ä»£è™Ÿ','åç¨±','å³æ™‚åƒ¹','æ¼²è·Œå¹…%','æŠ€è¡“åˆ†','é‡èƒ½åˆ†','æ”»æ“Šåˆ†']
                if 'ä¸»åŠ›å‹•å‘' in raw_df.columns: cols_to_show += ['ä¸»åŠ›å‹•å‘', 'æŠ•ä¿¡(å¼µ)', 'å¤–è³‡(å¼µ)']

                st.dataframe(
                    raw_df[cols_to_show].style
                    .format(fmt_score)
                    .background_gradient(subset=['æ”»æ“Šåˆ†'], cmap=cmap_pastel_red)
                    .background_gradient(subset=['æŠ€è¡“åˆ†'], cmap=cmap_pastel_blue)
                    .background_gradient(subset=['é‡èƒ½åˆ†'], cmap=cmap_pastel_green)
                    .map(color_change, subset=['æ¼²è·Œå¹…%']),
                    hide_index=True,
                    use_container_width=True
                )

    # === Tab 3: åº«å­˜ç®¡ç† (é‚è¼¯ç¶­æŒ) ===
    with tab_inv:
        # (é€™è£¡çš„ç¨‹å¼ç¢¼èˆ‡åŸæœ¬å®Œå…¨ç›¸åŒï¼Œçœç•¥ä»¥ç¯€çœç©ºé–“ï¼Œè«‹ç›´æ¥è¤‡è£½æ‚¨åŸæœ¬çš„åº«å­˜ç®¡ç†å€å¡Š)
        # å”¯ä¸€è¦ä¿®æ”¹çš„æ˜¯ï¼š
        # ç•¶è¦é¡¯ç¤ºåº«å­˜å³æ™‚å ±åƒ¹æ™‚ï¼Œä½¿ç”¨æ–°çš„ v32_df ä¾†å–å¾—åˆ†æ•¸
        st.subheader("ğŸ“ åº«å­˜äº¤æ˜“ç®¡ç†")
        
        # ç°¡å–®è¼‰å…¥åç¨±å°ç…§ (å¾ Drive Data å»ºç«‹)
        name_map = {}
        if not v32_df.empty:
            name_map = dict(zip(v32_df['ä»£è™Ÿ'], v32_df['åç¨±']))

        # ... (ä»¥ä¸‹äº¤æ˜“ç™»è¨˜ä»‹é¢ä»£ç¢¼èˆ‡æ‚¨åŸæœ¬çš„å®Œå…¨ç›¸åŒï¼Œè«‹ä¿ç•™) ...
        # (ç‚ºäº†å®Œæ•´æ€§ï¼Œè‹¥æ‚¨éœ€è¦æˆ‘å†è²¼ä¸€æ¬¡é€™éƒ¨åˆ†è«‹å‘Šè¨´æˆ‘)
        # ...
        
        st.divider()
        st.subheader("ğŸ“Š æŒè‚¡ç›£æ§")
        if not st.session_state['inventory'].empty:
            inv_df = st.session_state['inventory'].copy()
            inv_codes = inv_df['è‚¡ç¥¨ä»£è™Ÿ'].astype(str).tolist()
            inv_rt = get_realtime_quotes(inv_codes) 
            res = []
            score_map = v32_df.set_index('ä»£è™Ÿ')['æ”»æ“Šåˆ†'].to_dict() if not v32_df.empty else {}
            
            for idx, r in inv_df.iterrows():
                code = str(r['è‚¡ç¥¨ä»£è™Ÿ'])
                qty = float(r['æŒæœ‰è‚¡æ•¸'] or 0)
                cost = float(r['è²·å…¥å‡åƒ¹'] or 0)
                
                rt_info = inv_rt.get(code, {})
                curr = rt_info.get('å³æ™‚åƒ¹', 0)
                name = name_map.get(code, rt_info.get('åç¨±', code)) # æ”¹ç”¨ Drive Map
                sc = score_map.get(code, 0)
                
                val = curr * qty
                c_tot = cost * qty
                pl = val - c_tot
                roi = (pl/c_tot*100) if c_tot>0 else 0
                
                if roi < -10: action = "ğŸ›‘ åœæ"
                elif sc >= 60: action = "ğŸŸ¢ çºŒæŠ±"
                else: action = "ğŸ”» è³£å‡º"
                
                res.append({
                    'ä»£è™Ÿ': code, 'åç¨±': name, 'å³æ™‚åƒ¹': curr, 
                    'æç›Š': pl, 'å ±é…¬ç‡%': roi, 'æ”»æ“Šåˆ†': sc, 
                    'å»ºè­°æ“ä½œ': action, 'æŒæœ‰è‚¡æ•¸': qty, 'è³¼å…¥å‡åƒ¹': cost
                })
            
            if res:
                df_res = pd.DataFrame(res)
                # ... (é¡¯ç¤ºé‚è¼¯ä¸è®Š) ...
                st.dataframe(
                    df_res[['ä»£è™Ÿ', 'åç¨±', 'æŒæœ‰è‚¡æ•¸', 'è³¼å…¥å‡åƒ¹', 'å³æ™‚åƒ¹', 'æç›Š', 'å ±é…¬ç‡%', 'æ”»æ“Šåˆ†', 'å»ºè­°æ“ä½œ']].style
                    .format({'è³¼å…¥å‡åƒ¹':'{:.2f}', 'å³æ™‚åƒ¹':'{:.2f}', 'æç›Š':'{:+,.0f}', 'å ±é…¬ç‡%':'{:+.2f}%', 'æ”»æ“Šåˆ†':'{:.0f}'})
                    .map(color_surplus, subset=['æç›Š','å ±é…¬ç‡%'])
                    .map(color_action, subset=['å»ºè­°æ“ä½œ']),
                    use_container_width=True, hide_index=True
                )
        else: st.info("ç›®å‰ç„¡åº«å­˜ã€‚")

if __name__ == "__main__":
    main()
